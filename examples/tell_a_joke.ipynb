{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# How to call functions with chat models\n",
    "\n",
    "This notebook demonstrates how to use the Chat Completions API to call external functions to extend the capabilities of GPT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e71f33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install scipy --quiet\n",
    "!pip install tenacity --quiet\n",
    "!pip install tiktoken --quiet\n",
    "!pip install termcolor --quiet\n",
    "!pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab872c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T22:41:58.148850Z",
     "start_time": "2024-07-12T22:41:58.133412Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  \n",
    "\n",
    "GPT_MODEL = \"gpt-4o\"\n",
    "client = OpenAI()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "\n",
    "First let's define a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745ceec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T22:41:59.531820Z",
     "start_time": "2024-07-12T22:41:59.529870Z"
    }
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d1c99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T22:42:00.463896Z",
     "start_time": "2024-07-12T22:42:00.461258Z"
    }
   },
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "### Tell a Joke\n",
    "\n",
    "Let's define a function that tells a random joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e25069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T22:42:01.676606Z",
     "start_time": "2024-07-12T22:42:01.674348Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_joke():\n",
    "    \"\"\"Returns a random joke.\"\"\"\n",
    "    jokes = [\n",
    "        \"Why don't scientists trust atoms? Because they make up everything!\",\n",
    "        \"Why did the scarecrow win an award? Because he was outstanding in his field!\",\n",
    "        \"Why don't some couples go to the gym? Because some relationships don't work out!\",\n",
    "        \"I told my wife she should embrace her mistakes. She gave me a hug.\",\n",
    "        \"I'm reading a book on anti-gravity. It's impossible to put down!\",\n",
    "    ]\n",
    "    return random.choice(jokes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfc39899",
   "metadata": {},
   "source": [
    "Now let's define the tools we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518d6827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T22:42:03.726604Z",
     "start_time": "2024-07-12T22:42:03.154689Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_joke\",\n",
    "            \"description\": \"Get a random joke\",\n",
    "            \"parameters\": {},\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c999375",
   "metadata": {},
   "source": [
    "Now let's try to get a joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c42a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T22:42:05.778263Z",
     "start_time": "2024-07-12T22:42:05.277346Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": \"Tell me a joke\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "if assistant_message.tool_calls:\n",
    "    tool_call = assistant_message.tool_calls[0]\n",
    "    if tool_call.function.name == \"get_joke\":\n",
    "        joke = get_joke()\n",
    "        messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"name\": \"get_joke\", \"content\": joke})\n",
    "        final_response = chat_completion_request(messages, tools=tools)\n",
    "        print(final_response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
